{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c729cec",
   "metadata": {},
   "source": [
    "Atalov S.\n",
    "\n",
    "Fundamentals of Machine Learning and Artificial Intelligence\n",
    "\n",
    "# Lab 4: Implementing a Gradient Boosting Classifier from Scratch\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337d4b1",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "The goal of this lab is to develop a deeper understanding of ensemble learning methods by implementing a Gradient Boosting Classifier from scratch in Python. You will apply your implementation to predict survival on the Titanic dataset.\n",
    "\n",
    "\n",
    "### Requirements:\n",
    "1. **Data**: Use the Titanic dataset available from the [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) on Kaggle. You will need to perform data preprocessing (handle missing values, convert categorical data to numeric).\n",
    "\n",
    "2. **Implementation**:\n",
    "    - **`GradientBoostingClassifier` class**: Your class should have at least three methods:\n",
    "      - `fit(X, y)`: Method to train the model.\n",
    "      - `predict(X)`: Method to predict the target for given input.\n",
    "      - `score(X, y)`: Method to calculate the accuracy of the model.\n",
    "    - The classifier should use decision trees as the weak learners. You can use an existing implementation of decision trees (like `DecisionTreeRegressor` from `sklearn`) or write your own from scratch.\n",
    "\n",
    "3. **Evaluation**:\n",
    "    - Split the Titanic dataset into training and testing sets.\n",
    "    - Train your model on the training set and evaluate its performance on the test set.\n",
    "    - Plot the training and testing accuracy as a function of the number of boosting rounds.\n",
    "\n",
    "### Deliverables:\n",
    "1. **Code**: A Jupyter notebook containing all the code, comments explaining your logic, and any assumptions made.\n",
    "2. **Report**: A brief report explaining your findings, the performance of the model, and any challenges you faced during the implementation.\n",
    "\n",
    "### Tips:\n",
    "- Start by understanding the algorithm using resources like Chapter 10 of [\"The Elements of Statistical Learning\"](https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf).\n",
    "- Testing your algorithm on a simpler dataset (like the Iris dataset) can help you debug.\n",
    "\n",
    "### Submission:\n",
    "Submit the Jupyter notebook and the report via the ecourse by **11 May 2024 01:00**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393f39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfcf11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GradientBoostingClassifier:\n",
    "    def __init__(self, n_estimators=500, learning_rate=0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.models = []\n",
    "        self.weights = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #заполнение, чтобы были ошибки\n",
    "        y_pred = np.full(len(y), np.mean(y))\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - y_pred\n",
    "\n",
    "            tree = DecisionTreeRegressor(max_depth=2)\n",
    "            tree.fit(X, residuals)\n",
    "\n",
    "\n",
    "            update = self.learning_rate * tree.predict(X)\n",
    "            y_pred += update\n",
    "\n",
    "            self.models.append(tree)\n",
    "            self.weights.append(self.learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_pred = np.zeros(len(X))\n",
    "        for i, model in enumerate(self.models):\n",
    "            y_pred += self.weights[i] * model.predict(X)\n",
    "        return np.round(y_pred)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94692f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = \"https://raw.githubusercontent.com/lobachevksy/teaching/main/titanic/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae060a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7640449438202247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7374301675977654"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(titanic_train)\n",
    "\n",
    "data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "data['Age'].fillna(data['Age'].mean(), inplace=True)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "data = pd.get_dummies(data, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "X = data.copy()\n",
    "y = X.pop(\"Survived\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1)\n",
    "gb.fit(X_train.values, y_train.values) \n",
    "\n",
    "print(gb.score(X_train.values, y_train.values)) \n",
    "gb.score(X_test.values, y_test.values) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c1610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e573e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
